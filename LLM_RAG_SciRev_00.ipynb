{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1C_ovJQbugjANJzSj4csI46DCtVP4oGT5",
      "authorship_tag": "ABX9TyMmf3B/0rox2zMFJxwDwyzG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shakil1819/LLM-RAG-SCiRev/blob/main/LLM_RAG_SciRev_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHe5xhawMPQV",
        "outputId": "c643ce0c-2f7b-4f19-a15f-847f64a56baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install poppler-utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uqqq pip --progress-bar off\n",
        "!pip install -qqq langchain==0.0.173 --progress-bar off\n",
        "!pip install -qqq chromadb==0.3.23 --progress-bar off\n",
        "!pip install -qqq pypdf==3.8.1 --progress-bar off\n",
        "!pip install -qqq pygpt4all==1.1.0 --progress-bar off\n",
        "!pip install -qqq pdf2image==1.16.3 --progress-bar off"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXD2LvZGMgyg",
        "outputId": "05654bf2-229b-44f5-f3ea-bdfae1eb180b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import GPT4All\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from pdf2image import convert_from_path"
      ],
      "metadata": {
        "id": "mfTkdnByOGlu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wPfjXOPNcvh",
        "outputId": "247de9d2-3184-4480-c707-137b14581b50"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-17 16:00:38--  https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin\n",
            "Resolving gpt4all.io (gpt4all.io)... 104.26.1.159, 172.67.71.169, 104.26.0.159, ...\n",
            "Connecting to gpt4all.io (gpt4all.io)|104.26.1.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3785248281 (3.5G)\n",
            "Saving to: ‘ggml-gpt4all-j-v1.3-groovy.bin.2’\n",
            "\n",
            "ggml-gpt4all-j-v1.3 100%[===================>]   3.52G  55.3MB/s    in 78s     \n",
            "\n",
            "2023-10-17 16:01:56 (46.4 MB/s) - ‘ggml-gpt4all-j-v1.3-groovy.bin.2’ saved [3785248281/3785248281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = convert_from_path(\"/content/drive/MyDrive/Colab Notebooks/~Pictures/2023279689.pdf\", dpi=88)\n",
        "len(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78nZFsOyNzhe",
        "outputId": "68fb4e36-9072-4098-c41c-908ba7b7bf9e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Colab Notebooks/~Pictures/2023279689.pdf\")"
      ],
      "metadata": {
        "id": "F9aw8n0DP9CB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loader.load_and_split()"
      ],
      "metadata": {
        "id": "a4T8qRh_QEks"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7n0LYR1QHo2",
        "outputId": "07e61f4d-3d17-4e8c-f502-10524d950a57"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xygv17GQQLHO",
        "outputId": "11cf093e-58e5-4f74-c699-995fd6aa116a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CycleGAN-Based Data Augmentation with CNN\n",
            "and Vision Transformers (ViT) Models for\n",
            "Improved Maize Leaf Disease Classification\n",
            "Syed Taha Yeasin Ramadan\n",
            "Department of Computer Science and Engineering\n",
            "Military Institute of Science and Technology (MIST)\n",
            "Dhaka, Bangladesh\n",
            "tahayeasin11@gmail.comTanjim Sakib\n",
            "Department of Computer Science and Engineering\n",
            "Military Institute of Science and Technology (MIST)\n",
            "Dhaka, Bangladesh\n",
            "tsakib77@gmail.com\n",
            "Md. Ahsan Rahat\n",
            "Department of Computer Science and Engineering\n",
            "Military Institute of Science and Technology (MIST)\n",
            "Dhaka, Bangladesh\n",
            "ahsanrahat11@gmail.comShakil Mosharrof\n",
            "Department of Computer Science and Engineering\n",
            "Military Institute of Science and Technology (MIST)\n",
            "Dhaka, Bangladesh\n",
            "shakilmrf8@gmail.com\n",
            "Abstract —Crop losses pose a serious danger to global food\n",
            "security, and this problem also affects maize crops. To success-\n",
            "fully address this issue, precise disease detection techniques\n",
            "are required. However, a major hurdle to developing reliable\n",
            "models to address this issue is the dearth of datasets. In re-\n",
            "sponse, we present a novel approach that uses synthetic images\n",
            "created by CycleGAN to supplement constrained datasets. We\n",
            "thoroughly assessed deep learning models, such as ResNet50V2,\n",
            "DenseNet169, VGG16, VGG19, Xception, MobileNetV2, and\n",
            "emerging vision transformer models, such as ViT-B/16 and\n",
            "ViT-B/32, with a focus on the two critical classes of maize leaf\n",
            "diseases, blight and common rust. Notably, DenseNet169 per-\n",
            "formed better than other models with an accuracy of 98.48%,\n",
            "especially when trained on the CycleGAN-enhanced dataset.\n",
            "CycleGAN-augmented data outperformed the performance of\n",
            "the models trained solely on the original dataset, demonstrating\n",
            "the effectiveness of the augmentation approach in performance\n",
            "enhancement. By utilizing CycleGAN’s synthetic images, this\n",
            "study expands the field of maize leaf disease diagnosis and\n",
            "establishes DenseNet169 as a viable model for precise disease\n",
            "identification. The findings of the study have the potential\n",
            "to significantly revolutionize agricultural operations using ad-\n",
            "vanced maize disease detection techniques.\n",
            "Keywords —maize crops ,disease detection techniques ,syn-\n",
            "thetic images ,augmentation ,CycleGAN, deep learning models ,\n",
            "vision transformers ,accuracy .\n",
            "I. I NTRODUCTION\n",
            "Maize, scientifically known as Zea mays, is of critical\n",
            "importance in agriculture due to its numerous contributions\n",
            "to global food security, economic prosperity, and human\n",
            "well-being. Maize, being one of the world’s most frequently\n",
            "farmed crops, is a major food source for billions of people\n",
            "worldwide, particularly in Africa, Latin America, and Asia.\n",
            "Because of its adaptability, it is used to feed cattle in addition\n",
            "to humans, making it an important part of animal husbandry\n",
            "and the livestock business. In terms of annual production,\n",
            "maize is consistently one of the world’s highest-yieldingcrops. According to the Food and Agriculture Organization\n",
            "(FAO), global maize production has just surpassed 1.1\n",
            "billion metric tons, making it one of the primary contributors\n",
            "to global grain production [1]. This massive production\n",
            "reflects the crop’s tolerance to a wide range of climates\n",
            "and growing circumstances, making it a staple crop in both\n",
            "industrialized and developing countries. Notably, regions\n",
            "such as the United States, China, Brazil, and Argentina\n",
            "stand out as big maize producers, accounting for a sizable\n",
            "proportion of overall annual output.\n",
            "The worldwide maize production environment is not with-\n",
            "out difficulties, with one of the most significant setbacks\n",
            "being the impact of diseases on crop output and quality.\n",
            "Maize plants are susceptible to a variety of diseases, which\n",
            "can severely limit output levels, resulting in large economic\n",
            "losses for farmers and a negative impact on food security.\n",
            "Fungi, bacteria, and viruses, among others, contribute to\n",
            "these losses by creating diseases that impede plant growth,\n",
            "development, and overall production. The fungal disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=128)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "FKJmfnpcQVNL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_OcqwInQb8e",
        "outputId": "566ab77e-2b6e-4595-dd66-00f3a10245c5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IU5t4D2Qec9",
        "outputId": "ebd0b8e9-77b0-4f72-8ea6-a0627a0cc6d4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CycleGAN-Based Data Augmentation with CNN\n",
            "and Vision Transformers (ViT) Models for\n",
            "Improved Maize Leaf Disease Classification\n",
            "Syed Taha Yeasin Ramadan\n",
            "Department of Computer Science and Engineering\n",
            "Military Institute of Science and Technology (MIST)\n",
            "Dhaka, Bangladesh\n",
            "tahayeasin11@gmail.comTanjim Sakib\n",
            "Department of Computer Science and Engineering\n",
            "Military Institute of Science and Technology (MIST)\n",
            "Dhaka, Bangladesh\n",
            "tsakib77@gmail.com\n",
            "Md. Ahsan Rahat\n",
            "Department of Computer Science and Engineering\n",
            "Military Institute of Science and Technology (MIST)\n",
            "Dhaka, Bangladesh\n",
            "ahsanrahat11@gmail.comShakil Mosharrof\n",
            "Department of Computer Science and Engineering\n",
            "Military Institute of Science and Technology (MIST)\n",
            "Dhaka, Bangladesh\n",
            "shakilmrf8@gmail.com\n",
            "Abstract —Crop losses pose a serious danger to global food\n",
            "security, and this problem also affects maize crops. To success-\n",
            "fully address this issue, precise disease detection techniques\n",
            "are required. However, a major hurdle to developing reliable\n",
            "models to address this issue is the dearth of datasets. In re-\n",
            "sponse, we present a novel approach that uses synthetic images\n",
            "created by CycleGAN to supplement constrained datasets. We\n",
            "thoroughly assessed deep learning models, such as ResNet50V2,\n",
            "DenseNet169, VGG16, VGG19, Xception, MobileNetV2, and\n",
            "emerging vision transformer models, such as ViT-B/16 and\n",
            "ViT-B/32, with a focus on the two critical classes of maize leaf\n",
            "diseases, blight and common rust. Notably, DenseNet169 per-\n",
            "formed better than other models with an accuracy of 98.48%,\n",
            "especially when trained on the CycleGAN-enhanced dataset.\n",
            "CycleGAN-augmented data outperformed the performance of\n",
            "the models trained solely on the original dataset, demonstrating\n",
            "the effectiveness of the augmentation approach in performance\n",
            "enhancement. By utilizing CycleGAN’s synthetic images, this\n",
            "study expands the field of maize leaf disease diagnosis and\n",
            "establishes DenseNet169 as a viable model for precise disease\n",
            "identification. The findings of the study have the potential\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "MLjC1kAmQi-E"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_documents(texts, embeddings, persist_directory=\"db\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FQXuajAXmGD",
        "outputId": "c61e1fdf-dc8d-4c8f-90dc-866c4cb66c27"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_n_ctx = 1000\n",
        "model_path = \"./ggml-gpt4all-j-v1.3-groovy.bin.2\"\n",
        "llm = GPT4All(model=model_path, n_ctx=1000, backend=\"gptj\", verbose=False)"
      ],
      "metadata": {
        "id": "XDYaPzpeX-Eq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True,\n",
        "    verbose=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "-cjaqb7yYN2N",
        "outputId": "26e51bea-b787-4528-84c7-ad3396533130"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7f1aee4c102d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m qa = RetrievalQA.from_chain_type(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mchain_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"stuff\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mretriever\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"k\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mreturn_source_documents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RetrievalQA' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res = qa(\n",
        "    \"Your Task is to generate literature review.To generate a suitable prompt for extracting a literature review from a research paper, you can use the following format: In their study, [author name] et al. proposed [main outcomes of the research], achieving [best metrics obtained from the paper]. However, the researchers also acknowledged [limitations mentioned by the researcher]. This work contributes to the field by addressing [research gap].' - Here, you would replace [author name],[main outcomes of the research], [best metrics obtained from the paper], [limitations mentioned by the researcher], and [research gap] with specific information from the research paper you are interested in. This format provides a structured way to request the relevant information you need from the paper.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "gk1w2xH5YVGy",
        "outputId": "ab39c62f-eddb-4bdf-ba8a-7e6b7133ea5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'qa' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "wdNUy_ypZOc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res[\"Literature review : \"])\n"
      ],
      "metadata": {
        "id": "xNH7XYuMZP_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}